---
title: "The Bellabeat data analysis case study"
author: "Magdalena Malik"
date: "2023-06-17"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Case Study Roadmap

## ASK

BellaBeat is a successful small company with a potential to become a larger player in the global smart device market.
Company was founded in 2013 by Urška Sršen and Sando Mur, is a high-tech company that manufactures health-focused smart products.
Inspired by artistic approach of Urška Sršen, beautifully designed technology which is collecting data on activity, sleep, stress and reproductive health.

Bellabeat's cofounder and Chief Creative Officer, Urška Sršen, believes that analyzing smart device fitness data could help unlock new growth opportunities for the company.
The task is to focus on one of the BellaBeat's products and analyze smart device data to gain insight into how consumers are using their smart devices.

## PREPARE

The data set used for this analysis is public data set available on the Keggle website [FitBit Fitness Tracker Data](https://www.kaggle.com/datasets/arashnic/fitbit).
According to the source of the data set, data are generated by respondents to a distributed survey via Amazon Mechanical Turk between 03.12.2016-05.12.2016.
Data including information such as: daily activity, steps, calories and sleep habits.


Does my data ROCCC?

Reliable - Partly, data are collected from around 30 anonymous users, there is not much information about participants, also group seems to not be to big.

Original - No, data were collected by third party using Amazon Mechanical Turk.

Comprehensive - No, data sets are not complete, not all of them contain records from all participants.

Current - No, data was collected by period from 12/04/2016 to 12/05/201.

Cited - Yes, data are collected by credible organization.

Despite the fact that, our data are incomplete and there is no option to ask stockholders for upgrades, I will choose few data sets to prepare for analysis and get some insights into participants activity.

To get more information about available data sets it is time to load them.
I am going to use RStudio to determinate in details what given data sets are representing, which of them can be use for analysis purpose and how.

### Setting up my enviroments

Loading needed package:

```{r eval=FALSE}
library("here")
library("dplyr")
library("skimr")
library("janitor")
library("tidyr")
library("lubridate")
```

```{r include=FALSE, results='hide'}

library("here")
library("dplyr")
library("skimr")
library("janitor")
library("tidyr")
library("lubridate")

```

After setting up the environment,time to load all available data sets.

Loading all available data sets (18) and set the variable names accordingly.

```{r echo=TRUE}

activity <- read.csv("../project/dailyActivity_merged.csv")
calories <- read.csv("../project/dailyCalories_merged.csv")
intensities <- read.csv("../project/dailyIntensities_merged.csv")
steps <- read.csv("../project/dailySteps_merged.csv")
heart <- read.csv("../project/heartrate_seconds_merged.csv")
h_calories <- read.csv("../project/hourlyCalories_merged.csv")
h_intensities <- read.csv("../project/hourlyIntensities_merged.csv")
h_steps <- read.csv("../project/hourlySteps_merged.csv")
m_calories_n <- read.csv("../project/minuteCaloriesNarrow_merged.csv")
m_calories_w <- read.csv("../project/minuteCaloriesWide_merged.csv")
m_intensities_n <- read.csv("../project/minuteIntensitiesNarrow_merged.csv")
m_intensities_w <- read.csv("../project/minuteIntensitiesWide_merged.csv")
met <- read.csv("../project/minuteMETsNarrow_merged.csv")
sleep_m <- read.csv("../project/minuteSleep_merged.csv")
m_steps_n <- read.csv("../project/minuteStepsNarrow_merged.csv")
m_steps_w <- read.csv("../project/minuteStepsWide_merged.csv")
sleep_d <- read.csv("../project/sleepDay_merged.csv")
weight <- read.csv("../project/weightLogInfo_merged.csv")
```

Next step is checking which of loaded data sets can be used for our purpose.
NOTE: according to the description, data sets should contain 30 records (by user ID).

```{r echo=TRUE}

# check the amount of records for all data sets (by Id)
n_distinct(activity$Id) # 33
n_distinct(calories$Id) # 33
n_distinct(intensities$Id) # 33
n_distinct(steps$Id) # 33
n_distinct(h_calories$Id) # 33
n_distinct(h_intensities$Id) # 33
n_distinct(h_steps$Id) # 33
n_distinct(m_calories_n$Id) # 33
n_distinct(m_calories_w$Id) # 33
n_distinct(m_intensities_n$Id) # 33
n_distinct(m_intensities_w$Id) # 33
n_distinct(met$Id) # 33
n_distinct(m_steps_n$Id) # 33
n_distinct(m_steps_w$Id) # 33
n_distinct(sleep_m$Id) # 24
n_distinct(sleep_d$Id) # 24
n_distinct(weight$Id) # 8
n_distinct(heart$Id) # 14
n_distinct(sleep_m$Id) # 24
```

Not all of data sets contains desirable amount of records.
Since there is no chance to contact with stockholders to gain more accurate data sets, I will focus on few chosen one that, in my opinion, will be best fitting for further analysis.

Chosen data sets: 
  - activity,
  - calories,
  - intensities, 
  - steps.

## PROCESS


Process of cleaning I will start from the data set 'activity', which contains information about daily activity, steps, distance and calories.
I will use methods like:

```{r echo=TRUE}

skim_without_charts(activity)
head(activity)
glimpse(activity)
summary(activity)

```

To get the basic information about data set.
Chosen data set has 15 columns and 940 rows.
Data are ordered by 'Id' column and 'ActivityDate' column.
I have spotted that 'ActivityDate' column is in not correct format <chr>, for my purpose I will change it into date format.
I will rewrite it to new data set 'clean_activity' to keep original data separately.

```{r echo=TRUE}

clean_activity <- mutate(activity, ActivityDate=as.Date(ActivityDate, format = "%m/%d/%Y"))
glimpse(clean_activity)
```

Next step is to check column names by 'clean_names(clean_activity)':

```{r include=FALSE}
clean_names(clean_activity)

```

Check for missing values:

```{r echo=TRUE}
sum(is.na(clean_activity))
```

Check for duplicates rows:

```{r echo=TRUE}
sum(duplicated(clean_activity))
```

To be ready to work with data and get wanted information, I will also add week day to the table.

```{r include=FALSE}
clean_activity$WeekDay <- wday(clean_activity$ActivityDate, label=TRUE, week_start = 1)
```

Data set after cleaning will look like that:

```{r echo=FALSE}
head(clean_activity)
```

Next data set, that I am planning to use, would be data set created from 3 data sets containing information about intensities, calories and steps.

```{r echo=TRUE}
head(h_intensities)
head(h_calories)
head(h_steps)
```

Now I can merge data into one data set 'h_activity'.

```{r echo=TRUE}

h_activity <- merge(h_calories, h_steps, by=c('Id', 'ActivityHour'))
h_activity <- merge(h_activity, h_intensities, by=c('Id', 'ActivityHour'))
head(h_activity)
```

Here also I will do basic check of data set.

```{r include=FALSE}
clean_names(h_activity)
```

```{r echo=TRUE}
which(is.na(h_activity))

sum(is.na(h_activity))

sum(duplicated(h_activity))
```

All data looks correct, so now I will also add week day to the data set:

```{r include=FALSE}
h_activity$ActivityHour <- as.POSIXct(h_activity$ActivityHour, format = "%m/%d/%Y %I:%M:%S %p")
h_activity$WeekDay <- wday(h_activity$ActivityHour, label=TRUE, week_start = 1)
```

Now I will split 'ActivityHour' column into columns 'ActivityDate' and 'ActivityTime':

```{r views, include=FALSE}
h_activity <- tidyr::separate(h_activity,ActivityHour, c("ActivityDate", "ActivityTime"), sep = " ")
```

Note that 'ActivityDate' and 'ActivityTime' changed again into <chr> type.
Check the data set:

```{r echo=TRUE}
head(h_activity)
```

Now I can start processing plots and analysis on prepared data sets.

## ANALYZE AND SHARE

Install ggplot for plotting data
```{r include=FALSE}
#install.packages("ggplot2")
library("ggplot2")
```


Lets start from the first data set 'clean_activity', I will group and plot data to see how activity looks like in each day of the week.
First lets check steps, data will be grouped by week day and summed:

```{r echo=TRUE}
week_day_activity <- aggregate(clean_activity$TotalSteps, by=list(WeekDay=clean_activity$WeekDay), FUN=sum)
colnames(week_day_activity)[2] ="TotalSteps"
```

And now it can be plotted :

```{r echo=FALSE}
ggplot(data=week_day_activity, aes(WeekDay, TotalSteps, fill=TotalSteps))+
  geom_bar(position = "dodge", stat = "identity")+
  labs(title="Total amount of steps per Week Day")
```

Clearly we can see that the most active day is Tuesday, and the least active day is Sunday.
But also we can see that activity is not spread evenly thought out other week days.

Lets take a look on calories burn by week days:

```{r echo=TRUE}
week_day_calories <- aggregate(clean_activity$Calories, by=list(WeekDay=clean_activity$WeekDay), FUN=sum)
colnames(week_day_calories)[2] ="Calories"
```

```{r pressure, echo=FALSE}
ggplot(data=week_day_calories, aes(WeekDay, Calories, fill=Calories))+
  geom_bar(position = "dodge", stat = "identity")+
  labs(title="Total calories per week day")
```

As in the case of steps, also calories show similar pattern.
The highest burn is in Tuesday and the lowest in Sunday.
It seems that the Tuesday is the most active day in the week.

To see more related patterns, I will also plot the data, which storing information about activity by amount of minutes relatively to the week days.
Here we have four groups: - Very Active - Moderate - Light - Sedentary.

I will sum activity according to the day of the week to see how different level of activity are spread during the week, and also particular days.
To get to that point I have to group data by week day, sum them up and change format of data to long.

```{r include=FALSE}
# Sum data by week day.
sum_activity <- clean_activity[,c("WeekDay", "VeryActiveMinutes", "FairlyActiveMinutes", "LightlyActiveMinutes", "SedentaryMinutes")]
sum_activity_2 <- sum_activity %>% 
  group_by(WeekDay) %>% 
  summarise(VeryActiveMinutesTotal=sum(VeryActiveMinutes),
            FairlyActiveMinutesTotal=sum(FairlyActiveMinutes),
            LightlyActiveMinutesTotal=sum(LightlyActiveMinutes),
            SedentaryMinutesTotal=sum(SedentaryMinutes))

# Change format for long.
sum_activity_2_long <- sum_activity_2 %>% pivot_longer(cols=c( 'VeryActiveMinutesTotal', 'FairlyActiveMinutesTotal', 'LightlyActiveMinutesTotal', 'SedentaryMinutesTotal'),
                    names_to='Activity',
                    values_to='Minutes')
```

Plot data:

```{r echo=FALSE}
ggplot(data=sum_activity_2_long, aes(x=WeekDay, y=Minutes, fill=Activity))+
         geom_bar(stat = "identity")

```

Full day has 1440 minutes, so as we can see on the plot activity time is way shorter than sedentary time.
Mean value of total active minutes is 227.6342 and for sedentary time is 991.6607.
On average daily active time is around 18% of day.


To check how activity looks like during each week by hour, I will use second prepared data set 'h_activity'.
Firstly I will group data by week day and sort them by hour:

```{r echo=TRUE}
h_activity_grouped <- h_activity %>% group_by(WeekDay, ActivityTime) %>% arrange(ActivityTime) %>% 
  summarise(TotalCalories=mean(Calories),
            TotalSteps=mean(StepTotal),
            TotalIntensity=mean(TotalIntensity))
```

Sorted data are stored in new data set 'h_activity_grouped', so time to plot them and see how they are spread.

## --- 

```{r  echo=FALSE}
# Plot  calories data for each week day.
p1 <- ggplot(h_activity_grouped, aes(x=ActivityTime, y=TotalCalories, color=WeekDay))  + geom_point()
p1 + theme(axis.text.x = element_text(angle = 90)) + ggtitle("DAILY CALORIES PER WEEK DAY BY HOUR")
```

## --- 
```{r  echo=FALSE}
# Plot steps data for each week day.
p2 <- ggplot(h_activity_grouped, aes(x=ActivityTime, y=TotalSteps, color=WeekDay)) + geom_point()
p2 + theme(axis.text.x = element_text(angle = 90)) + ggtitle("DAILY STEPS PER WEEK DAY BY HOUR")
```

## --- 
```{r  echo=FALSE}
# Plot intensity data fo each week day.
p3 <- ggplot(h_activity_grouped, aes(x=ActivityTime, y=TotalIntensity, color=WeekDay)) + geom_point()
p3 + theme(axis.text.x = element_text(angle = 90)) + ggtitle("TOTAL INTENSITY PER WEEK DAY BY HOUR")
```

According to the daily activity, clearly we can see that the most active day is Tuesday. As to the hourly activity, hours between 8 am and 8 pm are the most active. It is worth to notice that values way above average are related to steps, calories and also intensity in Saturdays, but only in morning hours till noon.

## ACT

The BellaBeat is an application who can change the way people think about their activity. As we can clearly  see from above analysis, BellaBeat's users are not active as much as it is required, on top of that we can see that activity is not regular or constant through period of time. 
Key take would be to focus marketing campaign on adding option to application which will encourage users to take activity more often. 
Encouraging users will also be a key aspect in case of collecting data, since it is clear that users related to above case did not share their information about calories, heart rate and sleep, which are crucial information for further analysis. 


